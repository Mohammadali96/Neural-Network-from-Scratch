{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7a33ea-affd-4e7c-98a8-971efab1bafd",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9febf-1e99-4ad9-9a40-99901ebfe8e7",
   "metadata": {},
   "source": [
    "Here, I developed a four-layer NN without using Python libraries.\n",
    "\n",
    "Below is the shematic of a three-layer network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89bf6d-0b8c-493e-9d39-ab6a3da6f6ce",
   "metadata": {},
   "source": [
    "<img src=\"Capture1.PNG\" width = \"700\" height = \"340\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1043a-abe7-405b-b4d1-a5cbeb3f2e79",
   "metadata": {},
   "source": [
    "#### We only import Numpy and Pandas libraries for data loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c738fd3-a824-4a1f-9f8f-af8584ab686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7e6c3-d01e-4a85-98cf-8da370b2dfb4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056f686-aad3-43e8-a99c-e1fbaf41ffe7",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "###### Here, I used my seismic attributes at well locations as input data and facies well logs as labels!\n",
    "###### You can easiliy replace your excel file name and use the network for training your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa04caba-87c2-4176-849c-0bcd40028072",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_excel('F:/KrigNN/SeismicInWells_AllSar10.xlsx')\n",
    "data = file.to_numpy()\n",
    "inputs = data[:, :6] \n",
    "outputs = data[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e1904-0cb6-4453-8c6d-0f9fae4880a2",
   "metadata": {},
   "source": [
    "### Shufflling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c3e890-a8b7-4f2c-af14-e71e8ce685d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_list = np.random.permutation(len(data))\n",
    "inputs_sh = []\n",
    "outputs_sh = []\n",
    "for i in range(len(data)):\n",
    "    per_indx = per_list[i]\n",
    "    tmp_input = inputs[per_indx]\n",
    "    tmp_output = outputs[per_indx]\n",
    "    inputs_sh.append(tmp_input)\n",
    "    outputs_sh.append(tmp_output)\n",
    "\n",
    "inputs_sh = np.array(inputs_sh)\n",
    "outputs_sh = np.array(outputs_sh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd32056-0bbd-4d0a-8e1f-f37d8afe6111",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0940fb50-011a-48f2-8ed3-7693e96a7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vec = inputs_sh.min(axis=0)\n",
    "max_vec = inputs_sh.max(axis=0)\n",
    "inputs_sh = (inputs_sh - min_vec)/(max_vec - min_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc381e-079c-4465-b0b5-4361e3826ab1",
   "metadata": {},
   "source": [
    "### Train Test Splitting\n",
    "##### I used 80% of data for training the network!\n",
    "##### You can change it as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f6c94b-c584-41fd-a1c5-9de1b4778bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_test_split = int(0.8*len(inputs_sh))\n",
    "X_train = inputs_sh[0:trn_test_split, :]\n",
    "Y_train = outputs_sh[0:trn_test_split]\n",
    "\n",
    "X_val = inputs_sh[trn_test_split :, :]\n",
    "Y_val = outputs_sh[trn_test_split :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900f578-fb44-4c43-9cff-5756ad4799af",
   "metadata": {},
   "source": [
    "### Designing The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228c725e-d9dd-4ce1-903e-29a7008948ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 6 # input layer\n",
    "n1 = 8 # first hidden layer\n",
    "n2 = 4 # second hidden layer\n",
    "n3 = 1 # output layer\n",
    "\n",
    "w1 = np.random.uniform(low=-1,high= +1,size=(n1,n0))\n",
    "w2 = np.random.uniform(low=-1,high= +1,size=(n2,n1))\n",
    "w3 = np.random.uniform(low=-1,high= +1,size=(n3,n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9338b4-8c06-4fff-98a8-4970e983a996",
   "metadata": {},
   "source": [
    "#### Activation Function\n",
    "##### I used Sigmoid function\n",
    "<img src=\"Sigmoid.png\" width = \"500\" height = \"240\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401d9cd4-ad4b-49dc-8f60-cd6d9837d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    y = 1/(1 + np.exp(-1 * x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f24f3-6093-4604-af83-0806db0c003c",
   "metadata": {},
   "source": [
    "#### Feedforward Algorithm\n",
    "<img src=\"FeedForward.png\" width = \"500\" height = \"340\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c8ce29-46c3-47fd-b34f-2a662f516fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(input_net):\n",
    "    # inputs * w1 --> x1 , y1= sigmoid(x1) , y1 * w2 --> x2\n",
    "    # y2 = sigmoid(x2) , y2 * w3 --> x3 , y3 = sigmoid(x3) , y3 : output\n",
    "    x1 = np.dot(input_net , w1.T)\n",
    "    y1 = activation(x1)\n",
    "    x2 = np.dot(y1 , w2.T)\n",
    "    y2 = activation(x2)\n",
    "    x3 = np.dot(y2 , w3.T)\n",
    "    y3 = activation(x3)\n",
    "\n",
    "    return y1 , y2 , y3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba4344-2af5-4d5a-82ba-bf1b0c1f7d0d",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "To optimize the weights, we use Stochastic Gradient Decent (SGD): \n",
    "\n",
    "<img src=\"SGD.png\" width = \"800\" height = \"540\">\n",
    "\n",
    "Where E is the loss function (e.g. mean square error) and ðœ‚ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd7670-d64d-4754-a363-9a1669925b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_activation(out):\n",
    "    # y = sigmoid(x) --> d_y = y * (1 - y)\n",
    "    d_y = out * ( 1 - out)\n",
    "    return d_y\n",
    "\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "for i in range(epochs):\n",
    "    for j in range(len(X_train)):\n",
    "        input = X_train[j] # shape input = (n0,)\n",
    "        input = np.reshape(input , shape= (1,n0) ) # shape input = (1,n0)\n",
    "        target = Y_train[j]\n",
    "\n",
    "        y1 , y2 , y3 = feedforward(input)\n",
    "        error = target - y3\n",
    "\n",
    "        # w1 = w1 - lr * (-2/N)*(error) * d_f3 * w3 * d_f2 * w2 * d_f1 * ...\n",
    "        # ... * input\n",
    "        # (-2/N) * error : N-->1\n",
    "        # w1.shape = (n1 , n0)\n",
    "        # d_f3.shape = (1,n3) = (1,1)\n",
    "        # w3.shape = (n3 , n2) -- > d_f3 * w3 : shape= (1,n2)\n",
    "        # d_f2.shape = (1, n2) --> diagonal(d_f2) : shape= (n2,n2)\n",
    "        # d_f3 * w3 * diagonal(d_f2) --> shape = (1 , n2)\n",
    "        # w2.shape = ( n2 , n1)\n",
    "        # d_f3 * w3 * ( diagonal(d_f2) * w2 --> shape = (1,n1)\n",
    "        # d_f1.shape = (1, n1) --> diagonal(d_f1) --> shape = (n1 , n1)\n",
    "        # matrix1 * diagonal(d_f1) --> shape = (1, n1) --> matrix2.T --> shape=(n1,1)\n",
    "        # input.shape = (1 , n0)\n",
    "        # matrix2.T * input --> shape = (n1 , n0)\n",
    "\n",
    "        d_f3 = d_activation(y3)\n",
    "\n",
    "        d_f2 = d_activation(y2)\n",
    "        diag_d_f2 = np.diagflat(d_f2)\n",
    "\n",
    "        d_f1 = d_activation(y1)\n",
    "        diag_d_f1 = np.diagflat(d_f1)\n",
    "\n",
    "        temp1 = -2 * error * d_f3\n",
    "        temp2 = temp1 * w3 #np.dot(temp1 , w3)\n",
    "        temp3 = np.dot(temp2 , diag_d_f2)\n",
    "        temp4 = np.dot(temp3 , w2)\n",
    "        temp5 = np.dot(temp4 , diag_d_f1)\n",
    "        temp5 = temp5.T\n",
    "        temp6 = np.dot(temp5 , input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d69dea-95c2-46fe-b8cf-80287997acd4",
   "metadata": {},
   "source": [
    "#### First Layer Updating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7c0e0-210f-4815-b7b9-86d81e54cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        w1 = w1 - lr * temp6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d2c9b-e259-4776-a92d-f3e2ddb41adb",
   "metadata": {},
   "source": [
    "#### Second Layer Updating\n",
    "<img src=\"SecondLayer.png\" width = \"800\" height = \"540\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37365dfc-cdcb-4188-a7c6-2147d25f3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2 = w2 - lr * ((-2/N)*error * d_f3 * w3 * diag_d_f2).T * y1\n",
    "        w2 = w2 - lr * np.dot(temp3.T , y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bda53b-014a-4f36-b2ed-5af241405119",
   "metadata": {},
   "source": [
    "#### Third Layer Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca23fa2-bf4c-42bd-9d1b-ae885315103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # w3 = w3 - lr * (-2/N)*error * d_f3 * y2\n",
    "        w3 = w3 - lr * np.dot(temp1.T , y2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
